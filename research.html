
<!doctype html>
<html lang="en">
  <head>
  <script src="https://use.fontawesome.com/baff6f55f5.js"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Chaojie Ji</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-29643011-3', 'auto');
      ga('send', 'pageview');
    </script>

    <!-- New GA4 tracking code, see https://support.google.com/analytics/answer/10271001#analyticsjs-enable-basic --> 
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-311521642"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-311521642');
    </script>

    <!-- For all browsers -->
    <link rel="stylesheet" href="assets/css/academicons.min.css"/>
    <link rel="stylesheet" href="assets/css/academicons.css"/>
    
    <style>
      button.accordion {
      font:14px/1.5 Lato, "Helvetica Neue", Helvetica, Arial, sans-serif;
      cursor: pointer;
      padding: 0px;
      border: none;
      text-align: left;
      outline: none;
      font-size: 100%;
      transition: 0.3s;
      background-color: #f8f8f8;
      }
      button.accordion.active, button.accordion:hover {
      background-color: #f8f8f8;
      }
      button.accordion:after {
      content: " [+] ";
      font-size: 90%;
      color:#777;
      float: left;
      margin-left: 1px;
      }

      button.accordion.active:after {
      content: " [\2212] ";
      }
      div.panel {
      padding: 0 20px;
      margin-top: 5px;
      display: none;
      background-color: white;
      font-size: 100%;
      }
      div.panel.show {
      display: block !important;
      }
      .social-row {
        display: flex;
        flex-wrap: wrap;
        justify-content: space-between;
      }
    </style>
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Chaojie Ji</h1>
        <p>Ph.D. Student<br>The University of British Columbia</p>
        <!-- <p>Research Affiliate<br><a href="http://legacy.iza.org/en/webcontent/personnel/photos/index_html?key=24155">Institute for the Study of Labor (IZA)</a></p> -->
        <h3><a href="https://chaojieji.github.io/">Home</a></h3>
        <h3><a href="https://chaojieji.github.io/research.html">Research</a></h3>
    <b>Social</b><br>
        <div class="social-row">
          <a href="chaojiej@math.ubc.ca" class="author-social" target="_blank"><i class="fa fa-fw fa-envelope-square"></i> Email</a><br>
          <a href="https://orcid.org/0000-0001-5502-7508"><i class="ai ai-fw ai-orcid-square"></i> ORCID</a><br>
          <a href="http://github.com/chaojieji"><i class="fa fa-fw fa-github-square"></i> GitHub</a><br>
          <br>
        </div>
        <br>

    <p><b>Contact:</b><br>Department of Mathematics<br>The University of British Columbia<br>Leonard S. Klinck Building, 6356 Agricultural Rd.<br>Vancouver, BC V6T 1Z2</p>
    <p><small>Hosted on GitHub Pages</small></p>

      </header>
      <section>

    <h2><a id="published-papers-updated" class="anchor" href="#publications" aria-hidden="true"><span class="octicon octicon-link"></span></a>Published &amp; Forthcoming Papers</h2>
    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://ieeexplore.ieee.org/document/9537642">Graph Polish: A Novel Graph Generation Paradigm for Molecular Optimization.</a> <br> <b>Ji C.</b>, Zheng Y., Wang R., Cai Y., Wu H. <br> <i>IEEE Trans. Neural Netw. Learn. Syst.</i>, 2021. <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Molecular optimization, which transforms a given input molecule X into another Y with desired properties, is essential in molecular drug discovery. The traditional approaches either suffer from sample-inefficient learning or ignore information that can be captured with the supervised learning of optimized molecule pairs. In this study, we present a novel molecular optimization paradigm, Graph Polish. In this paradigm, with the guidance of the source and target molecule pairs of the desired properties, a heuristic optimization solution can be derived: given an input molecule, we first predict which atom can be viewed as the optimization center, and then the nearby regions are optimized around this center. We then propose an effective and efficient learning framework, Teacher and Student polish, to capture the dependencies in the optimization steps. A teacher component automatically identifies and annotates the optimization centers and the preservation, removal, and addition of some parts of the molecules; a student component learns these knowledges and applies them to a new molecule. The proposed paradigm can offer an intuitive interpretation for the molecular optimization result. Experiments with multiple optimization tasks are conducted on several benchmark datasets. The proposed approach achieves a significant advantage over the six state-of-the-art baseline methods. Also, extensive studies are conducted to validate the effectiveness, explainability, and time savings of the novel optimization paradigm. </p></div>
    <p style="margin:0"><button class="accordion">
      Online Appendix
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://ieeexplore.ieee.org/ielx7/5962385/6104215/9537642/supp1-3106392.pdf?arnumber=9537642">Online Appendix</a> </p></div>
    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/aI-area/T-S-polish">Data &amp; code for replication</a> <br></p></div>
    <p style="margin:0"><button class="accordion">
      Other versions
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://arxiv.org/abs/2008.06246">Initial version</a> (August 2020) <br> </p></div><br>
    <!--  -->

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://ieeexplore.ieee.org/document/9514513">Smoothness Sensor: Adaptive Smoothness-transition Graph Convolution for Attributed Graph Clustering.</a> <br> <b>Ji C.</b>, Chen H., Wang R., Cai Y., Wu H. <br> <i>IEEE Trans. Cybern.</i>, 2021. <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Clustering techniques attempt to group objects with similar properties into a cluster. Clustering the nodes of an attributed graph, in which each node is associated with a set of feature attributes, has attracted significant attention. Graph convolutional networks (GCNs) represent an effective approach for integrating the two complementary factors of node attributes and structural information for attributed graph clustering. Smoothness is an indicator for assessing the degree of similarity of feature representations among nearby nodes in a graph. Oversmoothing in GCNs, caused by unnecessarily high orders of graph convolution, produces indistinguishable representations of nodes, such that the nodes in a graph tend to be grouped into fewer clusters, and pose a challenge due to the resulting performance drop. In this study, we propose a smoothness sensor for attributed graph clustering based on adaptive smoothness-transition graph convolutions, which senses the smoothness of a graph and adaptively terminates the current convolution once the smoothness is saturated to prevent oversmoothing. Furthermore, as an alternative to graph-level smoothness, a novel fine-grained nodewise-level assessment of smoothness is proposed, in which smoothness is computed in accordance with the neighborhood conditions of a given node at a certain order of graph convolution. In addition, a self-supervision criterion is designed considering both the tightness within clusters and the separation between clusters to guide the entire neural network training process. The experiments show that the proposed methods significantly outperform 13 other state-of-the-art baselines in terms of different metrics across five benchmark datasets. In addition, an extensive study reveals the reasons for their effectiveness and efficiency. </p></div>
    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/aI-area/NASGC">Data &amp; code for replication</a> <br></p></div>
    <p style="margin:0"><button class="accordion">
      Other versions
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://arxiv.org/abs/2009.05743">Initial version</a> (August 2020) <br> </p></div><br>
    <!--  -->

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.sciencedirect.com/science/article/abs/pii/S0925231222004404">Perturb More, Trap More: Understanding Behaviors of Graph Neural Networks.</a> <br> <b>Ji C.</b>, Wang R., Wu H. <br> <i>Neurocomputing</i>, 2022. <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> While graph neural networks (GNNs) have shown great potential in various graph-related tasks, their lack of transparency has hindered our understanding of how they arrive at their predictions. The fidelity to the local decision boundary of the original model, indicating how well the explainer fits the original model around the instance to be explained, is neglected by existing GNN explainers. In this paper, we first propose a novel post hoc framework based on local fidelity for any trained GNNs, called TraP2, which can generate a high-fidelity explanation. Considering that both the relevant graph structure and important features inside each node must be highlighted, a three-layer architecture in TraP2 is designed: i) the interpretation domain is defined by the Translation layer in advance; ii) the local predictive behaviors of the GNNs being explained are probed and monitored by the Perturbation layer, in which multiple perturbations for graph structure and feature level are conducted in the interpretation domain; and iii) highly faithful explanations are generated by fitting the local decision boundary of GNNs being explained through the Paraphrase layer. We evaluated TraP2 on several benchmark datasets under the four metrics of accuracy, area under receiver operating characteristic curve, fidelity, and contrastivity, and the results prove that it significantly outperforms state-of-the-art methods. </p></div>
    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/aI-area/TraP2">Data &amp; code for replication</a> <br></p></div>
    <p style="margin:0"><button class="accordion">
      Other versions
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://arxiv.org/abs/2004.09808">Initial version</a> (August 2020) <br> </p></div><br>
    <!--  -->

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.sciencedirect.com/science/article/abs/pii/S0925231220306226">Cascade Architecture with Rhetoric Long Short-Term Memory for Complex Sentence Sentiment Analysis.</a> <br> <b>Ji C</b>. and Wu H. <br> <i>Neurocomputing</i>, 2020. <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> In a sentiment analysis task, it is essential to differentiate the various and sometimes even contradictory emotions in each segment and to judge the underlying true emotion of the whole sentence. Rhetorical structure theory hierarchically structures the relationships between segments and describes the effects of relations. This study proposes a flexible cascade architecture: the lower unit divides the sentence into segments and obtains their distributed representation vector; the upper rhetoric-based long short-term memory unit aggregates the information of every segment and applies the concrete hierarchical relation information to perform sentiment analysis. Auxiliary techniques, namely, data augmentation and relation clustering, are also proposed for preventing overfitting. The experiment results prove that the proposed cascade architecture and auxiliary techniques improve the traditional approaches in most cases, which shows 3.17% accuracy growth in the fine-grained classification and 1.41% in the binary tasks at most. Furthermore, the cascade architecture is flexible enough, which could be easily extended by combining the Rhetoric-LSTM unit with the state-of-the-art classification or pre-trained models if necessary. </p></div>
    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/aI-area/rhetoric-lstm-with-cascade-architecture">Data &amp; code for replication</a> <br></p></div>
    <br>
    <!--  -->


    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://ieeexplore.ieee.org/abstract/document/9625743">Focus, Fusion and Rectify: Context-Aware Learning for COVID-19 Lung Infection Segmentation.</a> <br> Wang R., <b>Ji C.</b>, Zhang Y., Li Y. <br> <i>IEEE Trans. Neural Netw. Learn. Syst.</i>, 2021. <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> The coronavirus disease 2019 (COVID-19) pandemic is spreading worldwide. Considering the limited clinicians and resources and the evidence that computed tomography (CT) analysis can achieve comparable sensitivity, specificity, and accuracy with reverse-transcription polymerase chain reaction, the automatic segmentation of lung infection from CT scans supplies a rapid and effective strategy for COVID-19 diagnosis, treatment, and follow-up. It is challenging because the infection appearance has high intraclass variation and interclass indistinction in CT slices. Therefore, a new context-aware neural network is proposed for lung infection segmentation. Specifically, the autofocus and panorama modules are designed for extracting fine details and semantic knowledge and capturing the long-range dependencies of the context from both peer level and cross level. Also, a novel structure consistency rectification is proposed for calibration by depicting the structural relationship between foreground and background. Experimental results on multiclass and single-class COVID-19 CT images demonstrate the effectiveness of our work. In particular, our method obtains the mean intersection over union (mIoU) score of 64.8%, 65.2%, and 73.8% on three benchmark datasets for COVID-19 infection segmentation. </p></div>
    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/mathwrx/Focus-Fusion-and-Rectify-Context-Aware-Learning-for-COVID-19-Lung-Infection-Segmentation">Data &amp; code for replication</a> <br></p></div>
    <br>
    <!--  -->

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://ieeexplore.ieee.org/document/9371309">A Short-term Prediction Model at the Early Stage of the COVID-19 Pandemic based on Multi-source Urban Data.</a> <br> Wang R., <b>Ji C.</b>, Jiang Z., Wu Y., Yin L., Li Y. <br> <i>IEEE Trans. Comput. Soc. Syst.</i>, 2021. <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> The ongoing coronavirus disease 2019 (COVID-19) pandemic spread throughout China and worldwide since it was reported in Wuhan city, China in December 2019. 4 589 526 confirmed cases have been caused by the pandemic of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), by May 18, 2020. At the early stage of the pandemic, the large-scale mobility of humans accelerated the spread of the pandemic. Rapidly and accurately tracking the population inflow from Wuhan and other cities in Hubei province is especially critical to assess the potential for sustained pandemic transmission in new areas. In this study, we first analyze the impact of related multisource urban data (such as local temperature, relative humidity, air quality, and inflow rate from Hubei province) on daily new confirmed cases at the early stage of the local pandemic transmission. The results show that the early trend of COVID-19 can be explained well by human mobility from Hubei province around the Chinese Lunar New Year. Different from the commonly-used pandemic models based on transmission dynamics, we propose a simple but effective short-term prediction model for COVID-19 cases, considering the human mobility from Hubei province to the target cities. The performance of our proposed model is validated by several major cities in Guangdong province. For cities like Shenzhen and Guangzhou with frequent population flow per day, the values of R^2 of daily prediction achieve 0.988 and 0.985. The proposed model has provided a reference for decision support of pandemic prevention and control in Shenzhen. </p></div>
    <br>
    <!--  -->

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://academic.oup.com/bib/article-abstract/24/1/bbac523/6918779">AdaPPI: identification of novel protein functional modules via adaptive graph convolution networks in a protein–protein interaction network.</a> <br> Chen H., Cai Y., <b>Ji C.</b>, Selvaraj G., Wei D., Wu H. <br> <i>Brief. Bioinformatics.</i>, 2022. <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Identifying unknown protein functional modules, such as protein complexes and biological pathways, from protein–protein interaction (PPI) networks, provides biologists with an opportunity to efficiently understand cellular function and organization. Finding complex nonlinear relationships in underlying functional modules may involve a long-chain of PPI and pose great challenges in a PPI network with an unevenly sparse and dense node distribution. To overcome these challenges, we propose AdaPPI, an adaptive convolution graph network in PPI networks to predict protein functional modules. We first suggest an attributed graph node presentation algorithm. It can effectively integrate protein gene ontology attributes and network topology, and adaptively aggregates low- or high-order graph structural information according to the node distribution by considering graph node smoothness. Based on the obtained node representations, core cliques and expansion algorithms are applied to find functional modules in PPI networks. Comprehensive performance evaluations and case studies indicate that the framework significantly outperforms state-of-the-art methods. We also presented potential functional modules based on their confidence. </p></div>
    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/aI-area/AdaPPI">Data &amp; code for replication</a> <br></p></div>
    <br>
    <!--  -->

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.sciencedirect.com/science/article/pii/S1361841522000470?via%3Dihub">Boundary-Aware Context Neural Network for Medical Image Segmentation.</a> <br> Wang R., Chen S., <b>Ji C.</b>, Fan J., Li Y. <br> <i>Med. Image Anal.</i>, 2022. <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Medical image segmentation can provide a reliable basis for further clinical analysis and disease diagnosis. With the development of convolutional neural networks (CNNs), medical image segmentation performance has advanced significantly. However, most existing CNN-based methods often produce unsatisfactory segmentation masks without accurate object boundaries. This problem is caused by the limited context information and inadequate discriminative feature maps after consecutive pooling and convolution operations. Additionally, medical images are characterized by high intra-class variation, inter-class indistinction and noise, extracting powerful context and aggregating discriminative features for fine-grained segmentation remain challenging. In this study, we formulate a boundary-aware context neural network (BA-Net) for 2D medical image segmentation to capture richer context and preserve fine spatial information, which incorporates encoder-decoder architecture. In each stage of the encoder sub-network, a proposed pyramid edge extraction module first obtains multi-granularity edge information. Then a newly designed mini multi-task learning module for jointly learning segments the object masks and detects lesion boundaries, in which a new interactive attention layer is introduced to bridge the two tasks. In this way, information complementarity between different tasks is achieved, which effectively leverages the boundary information to offer strong cues for better segmentation prediction. Finally, a cross feature fusion module acts to selectively aggregate multi-level features from the entire encoder sub-network. By cascading these three modules, richer context and fine-grain features of each stage are encoded and then delivered to the decoder. The results of extensive experiments on five datasets show that the proposed BA-Net outperforms state-of-the-art techniques. </p></div>
    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/mathwrx/BA-Net">Data &amp; code for replication</a> <br></p></div>
    <br>
    <!--  -->

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.sciencedirect.com/science/article/abs/pii/S0957417422004791">Cascaded context enhancement network for automatic skin lesion segmentation.</a> <br> Wang R., Chen S., <b>Ji C.</b>, Li Y. <br> <i>Expert Syst. Appl.</i>, 2022. <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Skin lesion segmentation is an important step for automatic melanoma diagnosis. Due to the non-negligible diversity of lesions from different patients, extracting powerful context for fine-grained semantic segmentation is still challenging today. Although the deep convolutional neural networks (CNNs) have made significant improvements on skin lesion segmentation, they often fail to reserve the spatial details and long-range dependencies context due to consecutive convolution striding and pooling operations inside CNNs. In this paper, we formulate a cascaded context enhancement neural network for automatic skin lesion segmentation. A new cascaded context aggregation (CCA) module with a gate-based information integration approach is proposed to sequentially and selectively aggregate original image and multi-level features from the encoder sub-network. The generated context is further utilized to guide discriminative features extraction by the designed context-guided local affinity (CGL) module. Furthermore, an auxiliary loss is added to the CCA module for refining the prediction. In our work, we evaluate our approach on four public skin dermoscopy image datasets. The proposed method achieves the Jaccard Index (JA) of 87.1%, 80.3%, 84.3%, and 86.6% on ISIC-2016, ISIC-2017, ISIC-2018, and PH2 datasets, which show highly competitive performance with other state-of-the-art models respectively. </p></div>
    <br>
    <!--  -->

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://www.frontiersin.org/articles/10.3389/fbioe.2020.00901/full?&utm_source=Email_to_authors_&utm_medium=Email&utm_content=T1_11.5e1_author&utm_campaign=Email_publication&field=&journalName=Frontiers_in_Bioengineering_and_Biotechnology&id=562521">Heterogeneous graph convolutional networks and matrix completion for miRNA-disease association prediction.</a> <br> Zhu R., <b>Ji C.</b>, Wang Y., Cai Y., Wu, H. <br> <i>Front. Biotechnol. Bioeng.</i>, 2020. <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Due to the cost and complexity of biological experiments, many computational methods have been proposed to predict potential miRNA-disease associations by utilizing known miRNA-disease associations and other related information. However, there are some challenges for these computational methods. First, the relationships between miRNAs and diseases are complex. The computational network should consider the local and global influence of neighborhoods from the network. Furthermore, predicting disease-related miRNAs without any known associations is also very important. This study presents a new computational method that constructs a heterogeneous network composed of a miRNA similarity network, disease similarity network, and known miRNA-disease association network. The miRNA similarity considers the miRNAs and their possible families and clusters. The information of each node in heterogeneous network is obtained by aggregating neighborhood information with graph convolutional networks (GCNs), which can pass the information of a node to its intermediate and distant neighbors. Disease-related miRNAs with no known associations can be predicted with the reconstructed heterogeneous matrix. We apply 5-fold cross-validation, leave-one-disease-out cross-validation, and global and local leave-one-out cross-validation to evaluate our method. The corresponding areas under the curves (AUCs) are 0.9616, 0.9946, 0.9656, and 0.9532, confirming that our approach significantly outperforms the state-of-the-art methods. Case studies show that this approach can effectively predict new diseases without any known miRNAs. </p></div>
    <p style="margin:0"><button class="accordion">
      Replication files
    </button>
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> <a href="https://github.com/aI-area/DMA">Data &amp; code for replication</a> <br></p></div>
    <br>
    <!--  -->

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://ieeexplore.ieee.org/document/9517671">WRS: A Novel Word-embedding Method for Real-time Sentiment with Integrated LSTM-CNN Model.</a> <br> Rasool A., Jiang Q., Qu Q., <b>Ji C.</b> <br> <i>In Proc. RCAR.</i>, 2021. <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Artificial Intelligence (AI) is a research-focused technology in which Natural Language Processing (NLP) is a core technology in AI. Sentiment Analysis (SA) aims to extract and classify the people's opinions by NLP. The Machine Learning (ML) and lexicon dictionaries have limited competency to efficiently analyze massive live media data. Recently, deep learning methods significantly enrich the accuracy of recent sentiment models. However, the existing methods provide the aspect-based extraction that reduces individual word accuracy if a sentence does not follow the aspect information in real-time. Therefore, this paper proposes a novel word embedding method for the real-time sentiment (WRS) for word representation. The WRS's novelty is a novel word embedding method, namely, Word-to-Word Graph (W2WG) embedding that utilizes the Word2Vec approach. The WRS method assembles the different lexicon resources to employ the W2WG embedding method to achieve the word feature vector. Robust neural networks leverage these features by integrating LSTM and CNN to improve sentiment classification performance. LSTM is utilized to store the word sequence information for the effective real-time SA, and CNN is applied to extract the leading text features for sentiment classification. The experiments are conducted on Twitter and IMDB datasets. The results demonstrate our proposed method's effectiveness for real-time sentiment classification. </p></div>
    <br>
    <!--  -->

    <p style="margin:0"> <a style="margin:0; font-size:100%; font-weight:bold" href="https://dl.acm.org/doi/abs/10.1145/3395260.3395284">Fully Convolutional Network based on Contrast Information Integration for Dermoscopic Image Segmentation.</a> <br> Chen S., <b>Ji C.</b>, Wang R., Wu H. <br> <i>In Proc. ICMAI.</i>, 2020. <br><button class="accordion"> 
    Abstract   
    </button>   
    <div class="panel" style="background-color: #F1F1F1; color: #666; padding: 10px;"><p> Melanoma is one of the most common human lethal cancers. Because the lesions have different shapes, sizes, colors, and low contrast, extracting powerful features for fine-grained skin lesion segmentation is still a challenging task today. In this paper, we propose a novel fully convolutional network based on contrast information integration for skin lesion segmentation, which effectively utilizes contrast information from each convolutional block in our network framework. Compared with existing skin lesion segmentation approaches, a new integration module is designed by combining the contrast information for extracting richer feature representation. Finally, we evaluate our method on the public ISIC 2017 challenge dataset and obtain the outstanding performance with the Jaccard Index (JA) of 79.9%, which is higher than other state-of-the-art methods for skin lesion segmentation. </p></div>
    <br>
    <!--  -->

    <hr>

    <h2><a id="works-in-progress" class="anchor" href="#workinprogress" aria-hidden="true"><span class="octicon octicon-link"></span></a>Works in Progress</h2>

      </section>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    <script> 
    var acc = document.getElementsByClassName("accordion");
    var i;

    for (i = 0; i < acc.length; i++) {
        acc[i].onclick = function(){
            this.classList.toggle("active");
            this.parentNode.nextElementSibling.classList.toggle("show");
      }
    }
    </script>
  </body>
</html>
